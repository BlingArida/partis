#!/usr/bin/env python
import argparse
import time
import random
import sys
import numpy
from multiprocessing import Process, active_children
from subprocess import check_output, CalledProcessError
import os
partis_dir = os.path.dirname(os.path.realpath(__file__)).replace('/bin', '')
if not os.path.exists(partis_dir):
    print 'WARNING current script dir %s doesn\'t exist, so python path may not be correctly set' % partis_dir
sys.path.insert(1, partis_dir + '/python')

import utils
import glutils
from partitiondriver import PartitionDriver

# ----------------------------------------------------------------------------------------
def default_parameter_dir(args):
    if args.infname is not None:
        label = args.infname[ : args.infname.rfind('.')]  # probably ok not to use the full path here
        label = label.replace('/', '_')
    else:
        label = 'no-need-for-a-name'  # maybe actually don't have a need for one, if there's no input file
    pdir = '_output/' + label
    return pdir

# ----------------------------------------------------------------------------------------
def check_maybe_auto_cache_parameters(args, gldir):
    auto_ran_cache_parameters = False
    if not args.simulate_partially_from_scratch and not os.path.exists(args.parameter_dir):
        print '  parameter dir \'%s\' does not exist, so first caching a new set of parameters, then running action \'%s\'' % (args.parameter_dir, args.action)
        parter = PartitionDriver(args, 'cache-parameters', gldir)  # if we're caching parameters, read initial gl info from <gldir> (then the final glfo gets written to the parameter dir)
        parter.cache_parameters()
        parter.clean()
        auto_ran_cache_parameters = True
    return auto_ran_cache_parameters

# ----------------------------------------------------------------------------------------
def set_default_parameter_dir(args):
    used_default_parameter_dir = False
    if args.parameter_dir is None and not args.simulate_partially_from_scratch:
        args.parameter_dir = default_parameter_dir(args)
        print '  using default parameter dir \'%s\'' % args.parameter_dir
        used_default_parameter_dir = True
    return used_default_parameter_dir

# ----------------------------------------------------------------------------------------
def run_simulation(args):
    from recombinator import Recombinator

    if args.n_sim_events / args.n_procs > args.n_trees:
        raise Exception('requested more simulated events per process (%d / %d = %d) than trees (%d) (you should increase --n-trees, so the clonal families don\'t mostly have the same tree)' % (args.n_sim_events, args.n_procs, args.n_sim_events / args.n_procs, args.n_trees))  # doesn't really need to be an exception, but just for now...
    if args.outfname is None:
        raise Exception('have to specify --outfname for simulation')
    if not args.n_sim_events > 0:
        raise Exception('--n-sim-events has to be a positivie number')
    if args.slurm:
        raise Exception('simulator parallelization does not handle slurm')
    if args.infname is not None:
        print '  note: --infname is not used when simulating'
    if args.n_max_queries != -1:
        print '  note: --n-max-queries is not used when simulating (use --n-sim-events to set the simulated number of rearrangemt events)'
    if args.parameter_dir is None and not args.simulate_partially_from_scratch:
        raise Exception('either --parameter-dir must be specified, or --simulate-partially-from-scratch must be set')
    if args.simulate_partially_from_scratch and args.parameter_dir is not None:
        raise Exception('you can\'t specify --parameter-dir if you also set --simulate-partially-from-scratch')

    if args.initial_germline_dir is None:  # if the gl info dir wasn't explicitly set on the command line, we have to decide what to use
        if args.parameter_dir is not None:  # if --parameter-dir was explicitly set, assume there's gl info in this --parameter-dir
            gldir = args.parameter_dir + '/' + args.parameter_type + '/' + glutils.glfo_dir
        else:  # otherwise use the default
            gldir = default_initial_germline_dir
    else:
        gldir = args.initial_germline_dir

    # ----------------------------------------------------------------------------------------
    def make_events(n_events, iproc, random_ints):  # NOTE all the different seeds! this sucks but is necessary to allow reproducibility
        reco = Recombinator(args, gldir, seed=args.seed+iproc, sublabel=str(iproc))
        for ievt in range(n_events):
            reco.combine(random_ints[ievt])

    print 'simulating'
    used_default_parameter_dir = set_default_parameter_dir(args)
    auto_ran_cache_parameters = check_maybe_auto_cache_parameters(args, gldir)

    n_per_proc = int(float(args.n_sim_events) / args.n_procs)

    # generate all the random seeds
    all_random_ints = []
    for iproc in range(args.n_procs):  # have to do it all at once, 'cause each of the subprocesses is going to reset its seed and god knows what happens to our seed at that point
        all_random_ints.append([random.randint(0, numpy.iinfo(numpy.int32).max) for i in range(n_per_proc)])

    if args.n_procs == 1:  # multiprocessing is kind of messy
        make_events(n_per_proc, 0, all_random_ints[0])
    else:  # start the processes and wait for 'em to finish
        for iproc in range(args.n_procs):
            proc = Process(target=make_events, args=(n_per_proc, iproc, all_random_ints[iproc]))
            proc.start()
        while len(active_children()) > 0:
            sys.stdout.flush()
            time.sleep(1)

    # check and merge output
    outfnames = [args.workdir + '/recombinator-' + str(iproc) + '/' + os.path.basename(args.outfname) for iproc in range(args.n_procs)]
    for fname in outfnames:
        if not os.path.exists(fname):
            raise Exception('output file %s d.n.e.' % fname)
        n_events = int(check_output('grep -v unique_id ' + fname + ' | awk -F, \'{print $2}\' | uniq | wc -l', shell=True).split()[0])  # if *adjacent* events have the same rearrangement parameters (and hence reco id), they'll show up as the same event. It has happened!
        if n_events < n_per_proc - 3:  # give ourselves a little breathing room for adjacent events that have the same rearrangement parameters (it's only happened once, ever, so maybe 3 is enough?)
            raise Exception('only found %d events (expected %d) in output file %s' % (n_events, n_per_proc, fname))
    utils.merge_csvs(args.outfname, outfnames)

# ----------------------------------------------------------------------------------------
def run_partitiondriver(args):
    args.queries = utils.get_arg_list(args.queries)
    args.reco_ids = utils.get_arg_list(args.reco_ids)
    args.n_max_per_region = utils.get_arg_list(args.n_max_per_region, intify=True)
    args.initial_match_mismatch = utils.get_arg_list(args.initial_match_mismatch, intify=True)
    args.annotation_clustering_thresholds = utils.get_arg_list(args.annotation_clustering_thresholds, floatify=True)
    args.naive_hamming_bounds = utils.get_arg_list(args.naive_hamming_bounds, floatify=True)
    if args.seed_unique_id is not None:
        args.seed_unique_id = args.seed_unique_id.strip()  # protect against the space you have to put in front of it if it's got an initial minus sign
    if args.sw_debug is None:  # if not explicitly set, set equal to regular debug
        args.sw_debug = args.debug
    if len(args.n_max_per_region) != 3:
        raise Exception('n-max-per-region should be of the form \'x:y:z\', but I got ' + str(args.n_max_per_region))
    if len(args.initial_match_mismatch) != 2:
        raise Exception('--initial-match-mismatch should be of the form \'match:mismatch\', but I got ' + str(args.n_max_per_region))
    if args.infname is None:
        raise Exception('--infname is required for the \'%s\' action' % args.action)

    used_default_parameter_dir = set_default_parameter_dir(args)

    gldir = default_initial_germline_dir
    if args.initial_germline_dir is not None:
        gldir = args.initial_germline_dir

    if args.action == 'cache-parameters':
        parter = PartitionDriver(args, 'cache-parameters', gldir)  # if we're caching parameters, read initial gl info from <args.initial_germline_dir> (then the final glfo gets written to the parameter dir)
        parter.cache_parameters()
        parter.clean()
        return

    auto_ran_cache_parameters = check_maybe_auto_cache_parameters(args, gldir)

    if args.initial_germline_dir is None:  # unless it was overridden on the command line, use the glfo in the parameter dir
        gldir = args.parameter_dir + '/' + args.parameter_type + '/' + glutils.glfo_dir

    parter = PartitionDriver(args, args.action, gldir)
    if 'run-' in args.action:
        parter.run_algorithm(args.action.replace('run-', ''))
    elif args.action == 'partition':
        parter.partition()
    else:
        raise Exception('bad action ' + args.action)
    parter.clean()

# ----------------------------------------------------------------------------------------
def view_existing_output(args):
    if args.outfname is None:
        raise Exception('--outfname is required for action \'%s\'' % args.action)
    if not os.path.exists(args.outfname):
        raise Exception('--outfname \'%s\' does not exist' % args.outfname)

    if args.initial_germline_dir is None:
        args.initial_germline_dir = default_initial_germline_dir

    parter = PartitionDriver(args, args.action, args.initial_germline_dir)
    if args.action == 'view-annotations':
        parter.view_existing_annotations()
    elif args.action == 'view-partitions':
        parter.view_existing_partitions()
    else:
        assert False
    parter.clean()

# ----------------------------------------------------------------------------------------
try:
    rows, columns = [int(v) for v in check_output(['stty', 'size']).split()]  # get actual tty height and width
except (OSError, CalledProcessError):
    rows, columns = 50, 200
formatter_class = lambda prog: argparse.HelpFormatter(prog, max_help_position=columns, width=columns)
parser = argparse.ArgumentParser(formatter_class=formatter_class)
subparsers = parser.add_subparsers(dest='action')

parent_parser = argparse.ArgumentParser(add_help=False)
parent_parser.add_argument('--debug', type=int, default=0, choices=[0, 1, 2], help='Debug verbosity level.')
parent_parser.add_argument('--sw-debug', type=int, choices=[0, 1, 2], help='Debug level for Smith-Waterman.')
parent_parser.add_argument('--is-data', action='store_true', help='deprecated! use --is-simu for simulation')
parent_parser.add_argument('--is-simu', action='store_true', help='Set if running on simulated sequences')
parent_parser.add_argument('--skip-unproductive', action='store_true', help='Skip sequences which Smith-Waterman determines to be unproductive (they have stop codons, are out of frame, etc.)')
parent_parser.add_argument('--seed', type=int, default=int(time.time()), help='Random seed for use (mostly) by recombinator (to allow reproducibility)')
parent_parser.add_argument('--no-indels', action='store_true', help='Skip smith-waterman matches that include indels. Note that this just *skips* them, you probably also want to increase the gap-open penalty to prevent vdjalign from finding them in the first place.')
parent_parser.add_argument('--only-csv-plots', action='store_true', help='only write csv plots')
parent_parser.add_argument('--seqfile', help='DEPRECATED use --infname instead')
parent_parser.add_argument('--infname', help='input sequence file in .fa, .fq or .csv (if .csv, specify id string and sequence headers with --name-column and --seq-column)')
parent_parser.add_argument('--name-column', default='unique_id', help='csv column name for sequence ids')
parent_parser.add_argument('--seq-column', default='seq', help='csv column name for nucleotide sequences')
parent_parser.add_argument('--parameter-dir', help='Directory to/from which to write/read sample-specific parameters. If not specified, a default location is used (and printed to std out). If it does not exist, we infer parameters before proceeding to the desired action.')
parent_parser.add_argument('--parameter-type', default='hmm', choices=('sw', 'hmm'), help='Use parameters from Smith-Waterman (sw) or the HMM (hmm) subdirectories for inference/simulation? (you should almost certainly use the hmm ones, but sw is occasionally useful for debugging)')
parent_parser.add_argument('--initial-germline-dir', help='Directory with fastas from which to read germline set. Only used when caching parameters, during which its contents is copied into --parameter-dir, perhaps (i.e. if specified) with modification. NOTE default is set below, because control flow is too complicated for argparse')
parent_parser.add_argument('--simulation-germline-dir', help='Germline directory that was used for simulation (not usually needed, in fact maybe only for performance evaluation)')
parent_parser.add_argument('--outfname', help='Output file name.')
parent_parser.add_argument('--sw-cachefname', help='Smith-Waterman cache file name. Default is set using a hash of all the input sequence ids (in partitiondriver, since we have to read the input file first).')
parent_parser.add_argument('--presto-output', action='store_true', help='write output file in presto format')
parent_parser.add_argument('--aligned-germline-fname', help='fasta file with alignments for each V gene')
parent_parser.add_argument('--plotdir', help='Base directory to which to write plots (no plots are written if this isn\'t set)')
parent_parser.add_argument('--ig-sw-binary', default=partis_dir + '/packages/ig-sw/src/ig_align/ig-sw', help='Path to ig-sw executable.')
parent_parser.add_argument('--workdir', help='Temporary working directory')
parent_parser.add_argument('--persistent-cachefname', help='Name of file which will be used as an initial cache file (if it exists), and to which all cached info will be written out before exiting.')
parent_parser.add_argument('--abbreviate', action='store_true', help='Abbreviate/translate sequence ids to improve readability of partition debug output. Uses a, b, c, ..., aa, ab, ...')
parent_parser.add_argument('--n-procs', default='1', help='Number of processes over which to parallelize (Can be colon-separated list: first number is procs for hmm, second (should be smaller) is procs for smith-waterman)')
parent_parser.add_argument('--n-max-procs', default=250, help='Never allow more processes than this (default %(default)d)')
parent_parser.add_argument('--n-max-to-calc-per-process', default=200, help='if a bcrham process calc\'d more than this many fwd + vtb values, don\'t decrease the number of processes in the next step (default %(default)d)')
parent_parser.add_argument('--slurm', action='store_true', help='Run multiple processes with slurm, otherwise just runs them on local machine. NOTE make sure to set <workdir> to something visible on all batch nodes.')
parent_parser.add_argument('--queries', help='Colon-separated list of query names to which we restrict ourselves')
parent_parser.add_argument('--reco-ids', help='Colon-separated list of rearrangement-event IDs to which we restrict ourselves')  # or recombination events
parent_parser.add_argument('--n-max-queries', type=int, default=-1, help='Maximum number of query sequences on which to run (except for simulator, where it\'s the number of rearrangement events)')
parent_parser.add_argument('--only-genes', help='Colon-separated list of genes to which to restrict the analysis')
parent_parser.add_argument('--n-max-per-region', default='3:5:2', help='Number of best smith-waterman matches (per region, in the format v:d:j) to pass on to the hmm')
parent_parser.add_argument('--default-v-fuzz', type=int, default=5, help='Size of the k space region over which to sum in the v direction')
parent_parser.add_argument('--default-d-fuzz', type=int, default=2, help='Size of the k space region over which to sum in the d direction')
parent_parser.add_argument('--gap-open-penalty', type=int, default=30, help='Penalty for indel creation in Smith-Waterman step.')
parent_parser.add_argument('--initial-match-mismatch', default='5:1', help='Initial match:mismatch scores for smith-waterman (we run several iterations, increasing mismatch each time).')
parent_parser.add_argument('--max-logprob-drop', type=float, default=5., help='stop glomerating when the total logprob has dropped by this much')
parent_parser.add_argument('--n-sets', type=int, default=1, help='Separate sequences into sets of size <n> before passing to hmm (i.e. \"k-hmm\").')
parent_parser.add_argument('--all-combinations', action='store_true', help='Run algorithm on *all* possible combinations of the input queries of length <n-sets> (otherwise, if <n-sets> is set, we run on sequential sets of <n-sets> in the input file).')
parent_parser.add_argument('--plot-performance', action='store_true', help='Write out plots comparing true and inferred distributions')
parent_parser.add_argument('--dont-rescale-emissions', action='store_true', help='Don\'t scale each hmm\'s emission probabilities to account for the branch length of each individual sequence.')
parent_parser.add_argument('--print-git-commit', action='store_true', help='print sys.argv, git commit hash, and tag info')
parent_parser.add_argument('--min-observations-to-write', type=int, default=20, help='When writing hmm model files, if we see a gene version fewer times than this, we average over other alleles, or other primary versions, etc. (see hmmwriter). NOTE default is manipulated in partitiondriver.py')
parent_parser.add_argument('--chain', default='h', choices=('h', 'k', 'l'), help='light chain is under development! only heavy chain works at the moment. But in the future: Are these heavy chain, or kappa or lambda light chain?')
parent_parser.add_argument('--species', default='human', choices=('human', 'mouse'), help='Which species?')
# parent_parser.add_argument('--use_mean_at_boundaries', action='store_true', help='see note in hmmwriter')
print 'TODO switch test.py to other germline dir instead of using --only-genes'
subconfig = {
    'version'          : {'func' : int, 'help' : 'print version information and exit'},
    'cache-parameters' : {'func' : run_partitiondriver, 'help' : 'Cache parameter values and write hmm model files.'},
    'run-viterbi'      : {'func' : run_partitiondriver, 'help' : 'Annotate sequences in input file, i.e. run the viterbi algorithm, using pre-existing parameter directory.'},
    'partition'        : {'func' : run_partitiondriver, 'help' : 'Partition sequences in input file into clonally-related families using pre-existing parameter directory.'},
    'simulate'         : {'func' : run_simulation,      'help' : 'Generate simulated sequences based on information in pre-existing parameter directory.'},
    'run-forward'      : {'func' : run_partitiondriver, 'help' : 'Run the forward algorithm on sequences in input file, using pre-existing parameter directory. Not particularly useful except for debugging.'},
    'view-annotations' : {'func' : view_existing_output,'help' : 'Print (to std out) the annotations from an existing annotation output csv.'},
    'view-partitions'  : {'func' : view_existing_output,'help' : 'Print (to std out) the partitions from an existing partition output csv.'}
}

subargs = {subname : [] for subname in subconfig}

subargs['cache-parameters'].append({'name' : '--generate-germline-set', 'kwargs' : {'action' : 'store_true', 'help' : 'still under development: starting from a minimal germline set, dynamically generate the germline set for this data.'}})
subargs['cache-parameters'].append({'name' : '--find-new-alleles', 'kwargs' : {'action' : 'store_true', 'help' : 'look for new alleles which are separated only by snps from existing alleles, add them to the existing germline set, and write it all to --parameter-dir.'}})
subargs['cache-parameters'].append({'name' : '--new-allele-fname', 'kwargs' : {'help' : 'fasta fname to which to write any new alleles (they are also written, with existing alleles, to --parameter-dir)'}})
subargs['cache-parameters'].append({'name' : '--debug-new-allele-finding', 'kwargs' : {'action' : 'store_true', 'help' : 'print lots of debug info on new allele fits'}})
subargs['cache-parameters'].append({'name' : '--only-smith-waterman', 'kwargs' : {'action' : 'store_true', 'help' : 'Exit after finishing smith-waterman. Doesn\'t write output file (yet).'}})

subargs['partition'].append({'name' : '--naive-hamming', 'kwargs' : {'action' : 'store_true', 'help' : 'agglomerate purely with naive hamming distance, i.e. set the low and high preclustering bounds to the same value'}})
subargs['partition'].append({'name' : '--naive-vsearch', 'kwargs' : {'action' : 'store_true', 'help' : 'Very fast clustering: infer naive (unmutated ancestor) for each input sequence, then toss it all into vsearch. But, of course, not as accurate as the slower methods.'}})
subargs['partition'].append({'name' : '--seed-unique-id', 'kwargs' : {'help' : 'Only look for sequences that are clonally related to this unique id. Much much much faster than partitioning the entire dataset.'}})
subargs['partition'].append({'name' : '--annotation-clustering', 'kwargs' : {'help' : 'Perform annotation-based clustering: group together sequences with the same V and J, same CDR3 length, and 90%% cdr identity. Very, very inaccurate.'}})
subargs['partition'].append({'name' : '--annotation-clustering-thresholds', 'kwargs' : {'default' : '0.9', 'help' : 'colon-separated list of thresholds for annotation-based (e.g. vollmers) clustering'}})
subargs['partition'].append({'name' : '--print-cluster-annotations', 'kwargs' : {'action' : 'store_true', 'help' : 'print annotation for each final cluster'}})
subargs['partition'].append({'name' : '--naive-hamming-bounds', 'kwargs' : {'help' : 'Clustering bounds (lo:hi colon-separated pair) on naive sequence hamming distance. If not specified, the bounds are set based on the per-dataset mutation levels. For most purposes should be left at the defaults.'}})
subargs['partition'].append({'name' : '--logprob-ratio-threshold', 'kwargs' : {'type' : float, 'default' : 18., 'help' : 'reaches a min value of <this> minus five for large clusters.'}})
subargs['partition'].append({'name' : '--synthetic-distance-based-partition', 'kwargs' : {'action' : 'store_true', 'help' : 'Use simulation truth info to create a synthetic distance-based partition (for validation).'}})
subargs['partition'].append({'name' : '--cache-naive-hfracs', 'kwargs' : {'action' : 'store_true', 'help' : 'In addition to naive sequences and log probabilities, also cache naive hamming fractions between cluster pairs. Only really useful for plotting or testing.'}})
subargs['partition'].append({'name' : '--n-precache-procs', 'kwargs' : {'type' : int, 'help' : 'Number of processes to use when precaching naive sequences. Default is set based on some heuristics, and should typically only be overridden for testing.'}})
subargs['partition'].append({'name' : '--biggest-naive-seq-cluster-to-calculate', 'kwargs' : {'type' : int, 'default' : 7, 'help' : 'start thinking about subsampling before you calculate anything if cluster is bigger than this'}})
subargs['partition'].append({'name' : '--biggest-logprob-cluster-to-calculate', 'kwargs' : {'type' : int, 'default' : 7, 'help' : 'start thinking about subsampling before you calculate anything if cluster is bigger than this'}})
subargs['partition'].append({'name' : '--n-partitions-to-write', 'kwargs' : {'type' : int, 'default' : 5, 'help' : 'Number of partitions (surrounding the best partition) to write to output file.'}})
subargs['partition'].append({'name' : '--naive-swarm', 'kwargs' : {'action' : 'store_true', 'help' : 'Use swarm instead of vsearch, which the developer recommends. Didn\'t seem to help much, and needs more work to optimize threshold, so DO NOT USE.'}})

subargs['simulate'].append({'name' : '--mutation-multiplier', 'kwargs' : {'type' : float, 'help' : 'Multiply observed branch lengths by some factor when simulating, e.g. if in data it was 0.05, but you want closer to ten percent in your simulation, set this to 2'}})
subargs['simulate'].append({'name' : '--mimic-data-read-length', 'kwargs' : {'action' : 'store_true', 'help' : 'trim V 5\' and D 3\' to mimic read lengths seen in data'}})
subargs['simulate'].append({'name' : '--n-sim-events', 'kwargs' : {'type' : int, 'default' : 1, 'help' : 'Number of rearrangement events to simulate'}})
subargs['simulate'].append({'name' : '--n-trees', 'kwargs' : {'type' : int, 'default' : 500, 'help' : 'Number of phylogenetic trees from which to choose during simulation (we pre-generate this many trees before starting a simulation run, then for each rearrangement event choose one at random -- so this should be at least of order the number of simulated events, so your clonal families don\'t all have the same tree).'}})
subargs['simulate'].append({'name' : '--n-leaves', 'kwargs' : {'type' : float, 'default' : 5., 'help' : 'Parameter describing the number of leaves per tree (maybe the mean, maybe not -- depends on the distribution)'}})
subargs['simulate'].append({'name' : '--constant-number-of-leaves', 'kwargs' : {'action' : 'store_true', 'help' : 'Give all trees the same number of leaves'}})
subargs['simulate'].append({'name' : '--n-leaf-distribution', 'kwargs' : {'default' : 'geometric', 'choices' : ['geometric', 'box', 'zipf'], 'help' : 'distribution from which to draw the number of leaves for each tree'}})
subargs['simulate'].append({'name' : '--indel-frequency', 'kwargs' : {'default' : 0., 'type' : float, 'help' : 'fraction of simulated sequences with indels'}})
# disabled for now, but if you want multiple indels per sequence you can use this (you'd also need to uncomment a line in recombinator):)
#subargs['simulate'].append({'name' : '--mean-n-indels', 'kwargs' : {'default' : 1, 'type' : int, 'help' : 'mean number of indels in each sequence which we\'ve already decided has indels (geometric distribution)'}})
subargs['simulate'].append({'name' : '--mean-indel-length', 'kwargs' : {'default' : 5, 'help' : 'mean length of each indel (geometric distribution)'}})
subargs['simulate'].append({'name' : '--indel-location', 'kwargs' : {'choices' : [None, 'v', 'cdr3'], 'help' : 'where to put the indels'}})
# NOTE command to generate gtr parameter file: [stoat] partis/ > zcat /shared/silo_researcher/Matsen_F/MatsenGrp/data/bcr/output_sw/A/04-A-M_gtr_tr-qi-gi.json.gz | jq .independentParameters | grep -v '[{}]' | sed 's/["\:,]//g' | sed 's/^[ ][ ]*//' | sed 's/ /,/' | sort >data/gtr.txt)
subargs['simulate'].append({'name' : '--gtrfname', 'kwargs' : {'default' : partis_dir + '/data/recombinator/gtr.txt', 'help' : 'File with list of GTR parameters. Fed into bppseqgen along with the chosen tree. Corresponds to an arbitrary dataset at the moment, but eventually will be inferred per-dataset.'}})
subargs['simulate'].append({'name' : '--simulate-partially-from-scratch', 'kwargs' : {'action' : 'store_true', 'help' : 'Don\'t use an existing parameter directory to describe the repertoire; instead start from scratch. Mutation freqs are harder, so for now we use some stuff in data/recombinator/.'}})
subargs['simulate'].append({'name' : '--scratch-mute-freq-dir', 'kwargs' : {'default' : partis_dir + '/data/recombinator/scratch-parameters', 'help' : 'see --simulate-partially-from-scratch'}})

subparsermap = {}
for name, vals in subconfig.items():
    subparsermap[name] = subparsers.add_parser(name, parents=[parent_parser], help=vals['help'], formatter_class=formatter_class)
    subparsermap[name].set_defaults(func=vals['func'])
    for argconf in subargs[name]:
        subparsermap[name].add_argument(argconf['name'], **argconf['kwargs'])

# ----------------------------------------------------------------------------------------
if '--action' in sys.argv:
    print '  NOTE we\'ve switched --action to a positional argument, so you can remove \'--action\' from your command line'
    sys.argv.remove('--action')

args = parser.parse_args()

args.partis_dir = partis_dir

# add OR of all arguments to all subparsers to <args>, as None (to avoid having to rewrite a *##!(%ton of other code)
for name in subconfig:
    for argconf in subargs[name]:
        if argconf['name'][:2] != '--':
            raise Exception('expected argument %s to be of form --<stuff>' % argconf['name'])
        argname = argconf['name'][2:].replace('-', '_')
        if argname not in args.__dict__:
            args.__dict__[argname] = None

if args.only_genes == 'TEST':
    args.only_genes = utils.test_only_genes
args.only_genes = utils.get_arg_list(args.only_genes)
args.n_procs = utils.get_arg_list(args.n_procs, intify=True)
args.n_fewer_procs = args.n_procs[0] if len(args.n_procs) == 1 else args.n_procs[1]
args.n_procs = args.n_procs[0]

if args.seqfile is not None and args.infname is None:
    print '  moving contents of deprecated option --seqfile into its replacement --infname'
    args.infname = args.seqfile

if args.only_genes is not None:
    for gene in args.only_genes:  # make sure they're all at least valid ig genes
        utils.split_gene(gene)

# if n_procs < 1 or n_procs > 9999:  # It happened, at least once. You know, probably.
#     raise Exception('bad n_procs %s' % n_procs)
if args.n_procs > args.n_max_procs:
    print 'reducing n procs %d to --n-max-procs %d' % (args.n_procs, args.n_max_procs)
    args.n_procs = args.n_max_procs
if args.n_fewer_procs > args.n_max_procs:
    print 'reducing n procs %d to --n-max-procs %d' % (args.n_fewer_procs, args.n_max_procs)
    args.n_fewer_procs = args.n_max_procs

if args.print_git_commit or args.action == 'version':
    print 'RUN ' + ' '.join(sys.argv)
    tag = check_output(['git', 'tag']).split()[-1]
    print '       tag %s' % tag
    print '    commit %s' % check_output(['git', 'rev-parse', 'HEAD']).strip()
    if args.action == 'version':
        sys.exit(0)

if args.is_data:  # if <is_data> was set on the command line, print a warning and continue
    print '  NOTE --is-data is no longer needed (it\'s the default; add --is-simu if running on simulation)'
    if args.is_simu:
        raise Exception('--is-data and --is-simu both set on the command line')
elif args.is_simu:
    pass  # args.is_data = False
else:  # if neither was given on the command line, set is_data to True
    args.is_data = True

if args.no_indels and args.gap_open_penalty < 1000:
    print 'forcing --gap-open-penalty to 1000 to prevent indels, since --no-indels was specified (you can also adjust this penalty directly)'
    args.gap_open_penalty = 1000

if args.workdir is None:  # set default here so we know whether it was set by hand or not
    args.workdir = '/tmp/' + os.path.basename(os.getenv('HOME')) + '/hmms/' + str(random.randint(0, 999999))
if os.path.exists(args.workdir):
    raise Exception('workdir %s already exists' % args.workdir)
if args.slurm and args.workdir.find('/tmp/') == 0:
    raise Exception('it appears that <workdir> isn\'t set to something visible to all slurm nodes')

if args.plot_performance:
    if args.plotdir is None:
        raise Exception('can\'t plot performance unless --plotdir is specified')
    if not args.is_simu:
        raise Exception('can\'t plot performance unless --is-simu is set')

if args.parameter_type != 'hmm':
    print '  using non-default parameter type \'%s\'' % args.parameter_type

if args.presto_output and args.aligned_germline_fname is None:
    raise Exception('in order to get presto output, you have to set --aligned-germline-fname (a fasta file with germline alignments for every germline gene)')

if args.parameter_dir is not None:
    args.parameter_dir = args.parameter_dir.rstrip('/')

default_initial_germline_dir = partis_dir + '/data/germlines/' + args.species

# ----------------------------------------------------------------------------------------
random.seed(args.seed)
start = time.time()
args.func(args)
print '      total time: %.1f' % (time.time()-start)
