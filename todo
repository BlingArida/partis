# now
#  - read

# print_reco_event:
#    - maybe simulation line shouldn't be associated with a particular inferred line (see below)
#    - fix multiple-indel printing'
#    - just print the length for large fv/jf insertions

# large cluster annotations seem to be way too willing to use ridiculously long insertions (e.g. in
#  - /fh/fast/matsen_e/processed-data/partis/kate-qrs-2016-09-09/seeds/QB850.402-Vh/Hs-LN1-5RACE-IgG-cluster-annotations.csv)
#  - /fh/fast/matsen_e/processed-data/partis/kate-qrs-2016-09-09/seeds/QB850.001-Vh/Hs-LN1-5RACE-IgG.log
#  - /fh/fast/matsen_e/processed-data/partis/kate-qrs-2016-09-09/seeds/QB850.417-Vh/Hs-LN1-5RACE-IgG.log

# fix ham scons test
# improve n_precache_proc calculator (expecially for large samples)
# auto-set clustering step procs (at least when seed partitioning, since you don't know before you remove other cdr3 lengths how many you'll have)
# fix waterer debug fails-to-rerun so they print uid
# is best-minus-x stuff still working? (I'm almost certain not -- I'm only calculating the partition log prob the last time through, so all the other times I can't rewind at all. I need to check that this isn't leading to too much over-mergin)
# add only-big-clusters option (well, probably make it the default, and allow to deactivate with --accurate-singletons)
# make sure sw cache file and diddle variable and whatnot are working as intended

# remove old parameters (e.g. qinfo) to get_kbounds)
# make sure new kbounds stuff works with fv/jf insertions
# deverbosify new kbounds stuff
# add kbounds to validation plots (i.e. flag queries for which kbounds didn't include true kset)
# add cdr3 mutation accuracy and cdr3 hamming to true naive
# kate data
# run on data in  /fh/fast/matsen_e/processed-data/cft/2016-10-21-rubelt-heritable-influence (/fh/fast/matsen_e/data/rubelt-heritable-influence-2016-10-21/proc_data/B-cell_memory.fasta /fh/fast/matsen_e/data/rubelt-heritable-influence-2016-10-21/proc_data/B-cell_naive.fasta)
# make sure new cdr3 length splitting in vsearch partitioning isn't really slow
# fix fuckup where vsearch partition gets its ccfs

# d right side mutation is still fucked

# partition/annotation validation
#  - go through a careful round of partition validation on larger samples (including light chain)
#  - double-check purity/completeness usage (should maybe take account of the fact that we remove duplicate sequences (and simulation should probably just forbid/remove duplicates) UPDATE oh wait but we're not removing duplicates in simulation)
#  - decide what you really want to do for ccf stuff and check_partition()
#  - rerun on other data sets

# improve hfrac bounds for vsearch (especially) and regular (maybe use only cdr3 hfrac?)
# should probably start writing cluster annotations by default
# make sure allele finding can't add the same sequence coming from different alleles

# simulation
#  - figure out whether GTR with current parameter setup actually makes sense to use
#  - --simulate-partially-from-scratch throws the out-of-frame exception if you don't use the allele finding testing --initial-germline-dir

# turn per-base mutation rates on
# non-slurm batch systems
# allow indels in both V and J at the same time (?)
# move dummy d adding in waterer to summarize_query()

# ?
#  - look at the stuff in _tmp/really-super-slow-kate-job/
#  - need to do allele removal for j (and maybe d?)

# figure out queries missing from missing_ids
#  - /fh/fast/matsen_e/processed-data/partis/kate-qrs-2016-09-09/seeds/QA255.016-Vh/Hs-LN3-5RACE-IgG-new.log
#  - /fh/fast/matsen_e/processed-data/partis/kate-qrs-2016-09-09/seeds/QA255.067-Vh/Hs-LN2-5RACE-IgG-new.log

# bryan's super-short-read sample
#  - figure out cause of mutation rate discontinuity in some clusters (better insertion mutation rate?)
#    - make a simulation sample with low, even mutation throughout v, d, and j, and see what you infer
#  - print cdr3 mutation rate (and maybe also make plots without dividing by length?)
#  - are mutation rates in J to left of tryp too high? (they're much higher than in the rest of J)
#  - try with no-indels?


# testing:
#  - make sure large fv/jf insertions are included
#  - don't run inference stuff on new parameters -- it should be fine to just run the new parameters (?)
#  - larger sample sizes
#  - at least make sure the seed cluster is big
#  - move testing off --only-genes
#  - bigger n-max-cluster-to-calc values
#  - can probably remove data stuff (UPDATE no, need to test .fa treatment and some code blocks -- but it can be a very small number of sequences)
#  - should switch to more typical workflow with no separate cache-parameters step
#  - needs at least a little light chain action
#  - make sure there's some multiple indels in the testing file
#  - add mutation-freq accuracy to metrics
#  - can probably stop deleting sw cache files
#  - also start using persistent cache files so you're not re-calculating the naive sequences at every step

# germline set generation:
# all alleles (including new ones) should have roughly the same mut freq distribution (especially at low mutation)'
# maybe remove bounds for as many fits as you can (i.e. don't pass bounds keyword to curvefit)
# collapse at least the largest clones before inferring new alleles'
# finish switch from fitfo to self.fitfos'
# try trevor's k-means-style-ish clustering idea
# maybe:
#   y-icpt (i.e. allele prevalence) could also go into the decision about whether to remove the template gene or not'
#   add requirement that all positions in multiple-snp alleles are correlated (?)'
#   do all the plots separately for each potential original snp base (i.e. separate plot for A, C, G, T)?'
#   add requirement for mulitple j genes for new alleles (?)'
#   increase n_max_mutations_per_segment for highly-mutated repertoires (?)'

# optimization
#  - could maybe switch to only checking the most likely j frame (maybe by moving backwards through j hmm?)
#  - go through glomerator (and maybe dphandler) and make sure everything that should be a reference or a pointer is one
#  - switch all the c++ map.count() calls to map.find()
#  - figure out a way to call naive_hfracs_.clear() without killing cpu usage
#  - switch only_genes in c++ to a set
#  - may be worthwhile to switch from colon-string hash map scheme to something shorter
#  - kbounds logical or should check if/handle case where one of them is unset (ok not really an optimization, but it's not very important atm)
#  - i think i could switch to running all the ksets of each gene at once (which would drastically reduce the dphandler trellis cache size, since we'd only need to keep one gene at a time), but this would involve a lot of careful rewriting in dphandler
#  - try to incorporate cdr3 length class stuff into loop optimizations in bcrham
#  - can v_match loop in get_padding_parameters() go outside the query loop?
#  - might make more sense to have the real insertions on the right side of v and d (instead of left side of d and j), since then we could easily skip k sets that didn't match the most likely frame (note that this would involve being really careful about all the places in the c++ and python where it assumes they're where they are now)
#  - it might make more sense to ditch the whole k_v k_d parameterization, since since it inherently suggests a rectangular region of k-space, which doesn't take account of the fact that we know beforehand that we shouldn't really be checking everything in that rectangular region
#    - maybe a stopgap would be to increment/decrement k_v/k_d in tandem?
#    - would make more sense to have per-gene kbounds
